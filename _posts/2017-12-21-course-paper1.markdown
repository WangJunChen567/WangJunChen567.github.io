---
layout: post
title: 从机器学习到迁移学习以及多目标进化算法
date: 2017-12-21 22:41:00 +0800
description: 在人工智能的发展过程中，规则学习、统计学习与深度学习依次出现。迁移学习利用相关数据与知识学习问题模型的特性，适合用于解决昂贵多目标优化问题。最近，已有算法框架将迁移学习运用到多目标进化算法，解决昂贵多目标优化问题。
img: course-paper1.jpg # Add image post (optional)
tags: [迁移学习, 多目标优化]
---
在人工智能的发展过程中，规则学习、统计学习与深度学习依次出现。迁移学习利用相关数据与知识学习问题模型的特性，适合用于解决昂贵多目标优化问题。最近，已有算法框架将迁移学习运用到多目标进化算法，解决昂贵多目标优化问题。                                     
## 从机器学习到迁移学习
### 人工智能与机器学习
人工智能诞生于60年前的达特茅斯会议。在人工智能问世后的一二十年（上世纪六十七年代），计算机的普及程度很低，不仅计算资源稀缺，而且可以利用的数据量也极其稀少。因此在当时的条件下，人工智能研究大部分是基于规则的思想。基于规则的思想持续了很多年，也得到了极大的发展。这种思想被成功应用甚至解决了一些不太灵活的人工智能问题，比如机器定理证明，专家系统等。但是对于机器学习、自然语言处理等更灵活的问题就很容易遇到规则爆炸、精度欠佳、矛盾规则等一系列问题，虽然后来出现的主观贝叶斯等不确定性推理等方法在努力寻求突破，但是总的来说，这些灵活的应用领域很快发展到了瓶颈。在计算机被大规模普及的上世纪90年代, 此时的计算机已具备足够高的计算性能，而计算机和互联网上也产生了越来越多的有规律的数据。于是，能够看出数据背后规律的统计思想渐渐成为人工智能研究的主流。用统计学的方法计算出数据背后的规律，而这个规律就是机器学习的目标。如今主流的机器学习方法，比如贝叶斯分类器、线性回归、逻辑回归、感知机、SVM、K近邻分类器等都是基于统计思想诞生的机器学习模型。
### 深度学习和迁移学习
如果把机器学习模型根据学习任务分类，可以划分为适合基于规则的方法（比如Web流量分类问题和一部分数据挖掘任务），合基于统计的方法（比如大部分数据挖掘任务），基于深度学习的方法（比如大数据条件下的图像语音识别问题），还有一些机器学习模型如决策树、随机森林等同时结合了规则学习与统计学习的思想。深度学习是是“连接主义”(下文会解释)的成功实现。连接主义的典型代表就是神经网络，浅层神经网络和深度神经网络（深度学习）都是。而连接主义的核心就是通过大量数据（样本）来训练边的连接强度，也就是神经网络中节点之间连线的权重。统计思想最大的贡献在于机器定理证明、规则与统计结合的决策树等。而深度学习对统计思想的冲击力主要集中在计算机视觉、语音识别等领域。但是，如今现在大部分的机器学习任务还是要靠统计学习的方法解决的，因为深度学习必须以大数据作训练，辅以高性能计算，而且当网络变大变深之后，海量数据训练出来的各个边的权重的意义几乎无从考究，于是深度学习便成了人们俗称的“黑匣子”，这在很多的机器学习任务中是致命的。迁移学习缺少模型支持，但是一旦取得重大突破，小样本学习时代将重磅出现。无需大数据和高性能计算，只需将某已有的模型按规则进行迁移，再辅以少量样本训练最后几层神经网络，即可达到深度学习甚至超越深度学习的效果。
## 迁移学习与多目标进化算法
### 昂贵多目标优化问题
在大多数现实世界的利益问题中，在评价解决方案的质量时，通常存在不止一个单一的标准。解决多目标优化问题（MOP）需要多种解决方案，这些解决方案代表了不同目标之间的最佳可能的权衡。这些解决方案传统上被称为帕累托最优解。进化算法（EAs）一般被认为是MOP的有效方法，主要是由于它们的隐式并行性，使得整个帕累托集合能够同时收敛。常见的多目标进化算法（MOEAs）需要进行大量的目标值评估，然后才能获取一组接近最优的解决方案。而在许多现实世界的应用中，每次评估可能相当昂贵（无论是在时间和/或任何其他有价值的资源方面）。一种常用的解决方法是使用替代品或元模型来近似昂贵的函数，然后搜索以更有效的全局优化为目标的近似EGO）。一种基于EGO框架但扩展计算成本较高的MOP的成熟算法是ParEGO遵循贝叶斯优化的路径，利用高斯过程回归模型的概率性质来智能地采样在搜索空间中可能以高概率为帕累托最优的那些点。这通常是通过在新的设计点上分配一个量化评估优点的预期改进措施来实现的，该设计点显示出在搜索空间的探索和利用之间提供了一个良好的平衡。目标的概率建模的关键优势在于它提供了一个原则性的方式来选择由真实（昂贵的）函数来评估的后续点，而不是更随机的MOEA方案。由此产生的样本效率可以大大节省计算工作量。其后提出的高斯过程模型结合MOEA / D算法被用来并行地处理多个候选解以聚合到帕累托集；参考向量指导的EA的高斯过程替代辅助扩展被证明对昂贵多目标问题具有特别的效力；另外，基于S度量选择的EGO（SMS-EGO）被提出来使用协方差矩阵适应演化策略来优化S度量。除此之外，还存在大量利用演化计算中的某种形式的函数近似的工作。虽然用代理辅助优化技术取得了显着的性能提升，但这些方法的局限性在于，它们只考虑源自当前目标感兴趣问题的数据，往往忽略了其他丰富的信息来源。特别是对于昂贵的问题，用来构建替代模型的目标数据的缺乏可能会阻碍搜索进度（通常称为冷启动问题），这鼓励我们寻找其他相关信息的来源。
### 迁移学习
为此，要指出的是，现实世界的问题很少孤立存在。新设计从以前完成的设计中抽取很多是很常见的。事实上，有效地建立在过去的经验和“经验教训”上的能力，对于在当今竞争激烈的世界取得成功至关重要。因此，为了提高优化过程的效率，通常存在可被利用的相关知识的真正的好处。在机器学习领域，利用相关源任务的知识来提高目标任务的学习的概念是迁移学习的核心前提，这是一个在各种应用中取得相当大成功的领域区域。然而，在优化领域中的知识转移的等价概念在很大程度上一直困扰着研究者，文献中只有少数相关的作品可用。如何有效的转移进化多目标优化与多问题替代方法，利用从不同的（但可能相关的）设计练习替代模型中嵌入的知识，以增加一个新的目标问题的优化。突出难点是适应性，就是说它可能来自多个来源的代理模型，例如以前完成的设计练习，或来自不同团队联合进行的相关设计项目。因此，期望有些来源可能与其他目标任务的相关性（或相关性）更为自然。在这种情况下，需要有方法能够自动调整必须发生转移的程度，并且原则上保证搜索的有效性。此外，实际可行性能够实现大规模数据存储和无缝通信设施的计算平台的支持。
## 最新的进展
在文章[1]中介绍了一个跨昂贵多目标优化问题的自适应知识转移的新框架~TEMO-MPS， 首次提出了多问题代理（MPS）的概念，提供了重用从不同（但可能相关的）解决问题的经验中获得的信息的能力，以增加目标任务的优化过程。 综合测试功能的实验结果，一个复杂的复合材料制造案例研究，以及机器学习模型的自动超参数调整的案例研究表明，TEMO-MPS可以显着优于ParEGO，通过相关的知识挖掘节省多达70％的功能评估。对结果进行更深入的分析表明，源任务和目标任务之间的相似性影响了TEMOMPS的可实现性能。特别是在理论上，TEMO-MPS中MPS模块的自适应特性在调节源模型贡献方面起着关键作用。当源与目标高度相关时，MPS利用这些关系大大加快目标优化任务的收敛特性。另一方面，当来源与目标无关时，可能的负面影响会自动减至最小。除了提供令人鼓舞的结果以证明知识转移在现实世界中的效用之外，拟议的框架还为大量研究机会打开了大门，以进一步探索优化中多重代理替代的范围。特别感兴趣的是处理跨异质搜索空间的任务间的知识转移，例如，当不同的优化任务的搜索空间维度不同时。



[1] A. T. W. Min, Y. S. Ong, A. Gupta and C. K.Goh, "Multi-Problem Surrogates: Transfer Evolutionary MultiobjectiveOptimization of Computationally Expensive Problems," in IEEE Transactionson Evolutionary Computation, vol. PP, no. 99, pp. 1-1
